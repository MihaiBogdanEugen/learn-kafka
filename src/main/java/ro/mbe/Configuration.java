package ro.mbe;

import org.apache.kafka.clients.consumer.RangeAssignor;
import org.apache.kafka.clients.producer.internals.DefaultPartitioner;
import org.apache.kafka.common.TopicPartition;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.apache.kafka.common.serialization.StringSerializer;
import ro.mbe.custom.CustomPartitioner;
import ro.mbe.custom.JsonSerializer;

import java.util.*;
import java.util.stream.Collectors;

class Configuration {

    private static final String[] KafkaServers = new String[] {
            "localhost:19101",
            "localhost:19102",
            "localhost:19103"
    };

    static final Map<String, List<Integer>> TopicsAndPartitions = new HashMap<>();

    static final int PollingTimeout = 1000;
    static final int NoOfRecordsToSend = 100;
    static final int NoOfRecordsToReceive = 100;
    static final boolean UseSubsciptionMethod = false;

    static {

        TopicsAndPartitions.put("sensors.first", Arrays.asList(0));
        TopicsAndPartitions.put("sensors.second", Arrays.asList(0, 1));
        TopicsAndPartitions.put("sensors.third", Arrays.asList(0, 1, 2));
    }

    static Collection<String> getAllTopics() {

        return TopicsAndPartitions.keySet();
    }

    static Collection<TopicPartition> getAllPartitions() {

        return Configuration.TopicsAndPartitions.entrySet()
                .stream()
                .flatMap(entry -> entry.getValue()
                        .stream()
                        .map(partition -> new TopicPartition(entry.getKey(), partition)))
                .collect(Collectors.toList());
    }

    /**
     * https://kafka.apache.org/documentation/#producerconfigs
     */
    static Properties getProducerConfig(String clientId) {

        Properties properties = new Properties();


        /** SETUP SETTINGS **/
        //  A list of host/port pairs to use for establishing the initial connection to the Kafka cluster
        properties.put("bootstrap.servers", String.join(", ", KafkaServers));

        //  Serializer class for key
        properties.put("key.serializer", JsonSerializer.class.getName());

        //  Serializer class for value
        properties.put("value.serializer", JsonSerializer.class.getName());

        //  An id string to pass to the server when making requests
        properties.put("client.id", clientId);

        //  Close idle connections after the number of milliseconds specified by this config
        properties.put("connections.max.idle.ms", 540000);  //9 minutes

        //  The compression type for all data generated by the producer.
        //  Valid values are none, gzip, snappy, or lz4.
        properties.put("compression.type", "none");

        //  Partitioner class that implements the Partitioner interface
        properties.put("partitioner.class", CustomPartitioner.class.getName());


        /** BATCHING SETTINGS **/
        //  The default batch size in bytes
        properties.put("batch.size", 16384);        //16 KB

        //  The total bytes of memory the producer can use to buffer records waiting to be sent to the server
        properties.put("buffer.memory", 33554432);  //32 MB

        //  The configuration controls how long KafkaProducer.send() and KafkaProducer.partitionsFor() will block
        properties.put("max.block.ms", 60000);      // 1 minute

        //  This setting gives the upper bound on the delay for batching: once we get batch.size worth of records for a
        //  partition it will be sent immediately regardless of this setting, however if we have fewer than this many
        //  bytes accumulated for this partition we will 'linger' for the specified time waiting for more records to show up
        properties.put("linger.ms", 0);             // no delay


        /** QUALITY OF SERVICE SETTINGS **/
        //  The number of acknowledgments the producer requires the leader to have received before considering a request complete.
        //  Valid values are '-1' ('all'), '0', '1'.
        properties.put("acks", "1");                //  Only leader acknowledgement

        //  How many times the producer will try to resend any record whose send fails with a potentially transient error
        properties.put("retries", 0);               // no retries

        //  The amount of time to wait before attempting to retry a failed request to a given topic partition
        properties.put("retry.backoff.ms", 100);    // .1 seconds

        //  The maximum number of unacknowledged requests the client will send on a single connection before blocking
        properties.put("max.in.flight.requests.per.connection", 5);

        return properties;
    }

    /**
     * https://kafka.apache.org/documentation/#consumerconfigs
     */
    static Properties getConsumerConfig(String clientId, String groupId) {

        Properties properties = new Properties();


        /** SETUP SETTINGS **/
        // A list of host/port pairs to use for establishing the initial connection to the Kafka cluster
        properties.put("bootstrap.servers", String.join(", ", KafkaServers));

        //  Deserializer class for key
        properties.put("key.deserializer", JsonSerializer.class.getName());

        //  Deserializer class for value
        properties.put("value.deserializer", JsonSerializer.class.getName());

        //  An id string to pass to the server when making requests
        properties.put("client.id", clientId);

        //  Close idle connections after the number of milliseconds specified by this config
        properties.put("connections.max.idle.ms", 540000);  //  9 minutes


        /** QUALITY OF SERVICE SETTINGS **/
        //  If true the consumer's offset will be periodically committed in the background
        properties.put("enable.auto.commit", true);

        //  The frequency in milliseconds that the consumer offsets are auto-committed to Kafka if enable.auto.commit is set to true
        properties.put("auto.commit.interval.ms", 5000);    //  5 seconds

        //  What to do when there is no initial offset in Kafka or if the current offset does not exist any more on the server
        //  Valid values are:
        //  - 'earliest': automatically reset the offset to the earliest offset
        //  - 'latest': automatically reset the offset to the latest offset
        //  - 'none': throw exception to the consumer if no previous offset is found for the consumer's group
        properties.put("auto.offset.reset", "latest");

        //  The amount of time to wait before attempting to retry a failed request to a given topic partition
        properties.put("retry.backoff.ms", 100);            //  0.1 seconds

        //  Automatically check the CRC32 of the records consumed
        properties.put("check.crcs", true);


        /** GROUPING SETTINGS **/
        if (groupId != null && groupId.length() > 0) {
            //  A unique string that identifies the consumer group this consumer belongs to
            properties.put("group.id", groupId);

            //  The expected time between heartbeats to the consumer coordinator when using Kafka's group management facilities
            properties.put("heartbeat.interval.ms", 3000);  // .33 seconds

            //  The timeout used to detect consumer failures when using Kafka's group management facility
            properties.put("session.timeout.ms", 10000);    // 10 seconds

            //  The class name of the partition assignment strategy that the client will use to distribute partition ownership amongst consumer instances when group management is used
            properties.put("partition.assignment.strategy", RangeAssignor.class.getName());    // 10 seconds

            //  The maximum delay between invocations of poll() when using consumer group management
            properties.put("max.poll.interval.ms", 300000);
        }


        /** THROTTLING SETTINGS **/
        //  The minimum amount of data the server should return for a fetch request
        properties.put("fetch.min.bytes", 1);                   //  1 byte

        //  The maximum amount of time the server will block before answering the fetch request if there isn't sufficient data to immediately satisfy the requirement given by fetch.min.bytes
        properties.put("fetch.max.wait.ms", 500);               // 0.5 seconds

        //  The maximum amount of data per-partition the server will return
        properties.put("max.partition.fetch.bytes", 1048576);   // 1 Mb

        //  The maximum number of records returned in a single call to poll()
        properties.put("max.poll.records", 500);

        return properties;
    }
}
